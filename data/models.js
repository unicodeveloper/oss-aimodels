const modelsDatabase = [
    {
        name: "LLaMA 2",
        author: "Meta",
        provider: "Hugging Face",
        category: "language",
        description: "A collection of pretrained and fine-tuned large language models ranging from 7B to 70B parameters.",
        plainDescription: "A powerful AI that can have conversations, answer questions, write content, and help with various text tasks.",
        useCases: ["Chatbots", "Content Writing", "Code Assistance", "Question Answering", "Text Summarization"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B - 70B",
            memoryRequired: "14GB - 140GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "GGUF", "AWQ"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Custom",
        downloads: "2.5M",
        stars: "45.2K",
        date: "2023-07-18",
        tags: ["transformer", "instruction-following", "chat"],
        githubUrl: "https://github.com/facebookresearch/llama",
        huggingtfaceUrl: "https://huggingface.co/meta-llama"
    },
    {
        name: "Stable Diffusion XL",
        author: "Stability AI",
        provider: "Hugging Face",
        category: "vision",
        description: "Latest text-to-image generation model with improved image quality and composition adherence.",
        plainDescription: "Creates high-quality images from text descriptions. Just type what you want to see and it generates the image.",
        useCases: ["Art Generation", "Marketing Materials", "Concept Art", "Social Media Content", "Product Mockups"],
        inputModalities: ["Text"],
        outputModalities: ["Image"],
        technicalSpecs: {
            parameters: "3.5B",
            memoryRequired: "8GB VRAM",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["Diffusers", "ONNX", "SafeTensors"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "OpenRAIL++",
        downloads: "1.8M",
        stars: "32.1K",
        date: "2023-07-26",
        tags: ["diffusion", "text-to-image", "generative"],
        githubUrl: "https://github.com/Stability-AI/generative-models",
        huggingtfaceUrl: "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0"
    },
    {
        name: "Whisper",
        author: "OpenAI",
        provider: "Hugging Face",
        category: "audio",
        description: "Automatic speech recognition system trained on 680,000 hours of multilingual data.",
        plainDescription: "Converts speech to text in 99+ languages. Upload audio files and get accurate transcriptions.",
        useCases: ["Meeting Transcription", "Podcast Subtitles", "Voice Notes", "Language Learning", "Accessibility"],
        inputModalities: ["Audio"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "39M - 1.55B",
            memoryRequired: "1GB - 10GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "TensorFlow", "ONNX", "CoreML"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "950K",
        stars: "58.3K",
        date: "2022-09-21",
        tags: ["speech-recognition", "multilingual", "transcription"],
        githubUrl: "https://github.com/openai/whisper",
        huggingtfaceUrl: "https://huggingface.co/openai/whisper-large-v3"
    },
    {
        name: "CLIP",
        author: "OpenAI",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Connects text and images, learning visual concepts from natural language supervision.",
        plainDescription: "Understands both images and text together. Can search images by description or classify images without training.",
        useCases: ["Image Search", "Content Moderation", "Image Classification", "Visual Q&A", "Recommendation Systems"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Embeddings"],
        technicalSpecs: {
            parameters: "428M",
            memoryRequired: "2GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "ONNX", "TensorFlow"],
            toolCalling: "No",
            reasoning: "Basic",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "1.2M",
        stars: "19.8K",
        date: "2021-01-05",
        tags: ["vision-language", "zero-shot", "contrastive"],
        githubUrl: "https://github.com/openai/CLIP",
        huggingtfaceUrl: "https://huggingface.co/openai/clip-vit-large-patch14"
    },
    {
        name: "Sentence Transformers",
        author: "UKP Lab",
        provider: "Hugging Face",
        category: "embedding",
        description: "Framework for state-of-the-art sentence, text and image embeddings.",
        plainDescription: "Converts text into numerical representations that capture meaning. Finds similar sentences and enables semantic search across documents.",
        useCases: ["Document Search", "Text Similarity", "Clustering", "Recommendation Systems", "FAQ Matching"],
        inputModalities: ["Text"],
        outputModalities: ["Embeddings"],
        technicalSpecs: {
            parameters: "22M - 335M",
            memoryRequired: "1GB - 4GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "TensorFlow", "ONNX", "Sentence-Transformers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "3.1M",
        stars: "13.5K",
        date: "2019-08-27",
        tags: ["embeddings", "similarity", "semantic-search"],
        githubUrl: "https://github.com/UKPLab/sentence-transformers",
        huggingtfaceUrl: "https://huggingface.co/sentence-transformers"
    },
    {
        name: "CodeT5",
        author: "Salesforce",
        provider: "Hugging Face",
        category: "language",
        description: "Unified pre-trained encoder-decoder Transformer for code understanding and generation.",
        plainDescription: "AI assistant for programming tasks. Understands code, generates new code, explains functions, and helps with debugging across multiple programming languages.",
        useCases: ["Code Generation", "Bug Fixing", "Code Documentation", "Code Translation", "API Generation"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "60M - 770M",
            memoryRequired: "2GB - 8GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "TensorFlow", "ONNX"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "450K",
        stars: "2.1K",
        date: "2021-09-02",
        tags: ["code-generation", "programming", "transformer"],
        githubUrl: "https://github.com/salesforce/CodeT5",
        huggingtfaceUrl: "https://huggingface.co/Salesforce/codet5-large"
    },
    {
        name: "YOLOv8",
        author: "Ultralytics",
        provider: "Ultralytics",
        category: "vision",
        description: "State-of-the-art real-time object detection, instance segmentation and image classification.",
        plainDescription: "Detects and identifies objects in images and videos in real-time. Can recognize people, cars, animals, and thousands of other objects instantly.",
        useCases: ["Security Cameras", "Autonomous Vehicles", "Quality Control", "Sports Analytics", "Retail Analytics"],
        inputModalities: ["Image", "Video"],
        outputModalities: ["Annotations"],
        technicalSpecs: {
            parameters: "3M - 68M",
            memoryRequired: "1GB - 4GB VRAM",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "ONNX", "TensorRT", "CoreML", "OpenVINO"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "GPL-3.0",
        downloads: "2.8M",
        stars: "22.4K",
        date: "2023-01-10",
        tags: ["object-detection", "real-time", "computer-vision"],
        githubUrl: "https://github.com/ultralytics/ultralytics",
        huggingtfaceUrl: "https://huggingface.co/spaces/Ultralytics/YOLOv8"
    },
    {
        name: "MusicGen",
        author: "Meta",
        provider: "Hugging Face",
        category: "audio",
        description: "Controllable music generation model that produces high-quality music samples.",
        plainDescription: "Creates original music from text descriptions. Specify genre, mood, instruments, and style to generate custom soundtracks and melodies.",
        useCases: ["Content Creation", "Game Soundtracks", "Advertisement Music", "Podcast Intros", "Creative Composition"],
        inputModalities: ["Text"],
        outputModalities: ["Audio"],
        technicalSpecs: {
            parameters: "300M - 3.3B",
            memoryRequired: "4GB - 16GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "CC-BY-SA",
        downloads: "380K",
        stars: "14.7K",
        date: "2023-06-08",
        tags: ["music-generation", "audio-synthesis", "controllable"],
        githubUrl: "https://github.com/facebookresearch/audiocraft",
        huggingtfaceUrl: "https://huggingface.co/facebook/musicgen-large"
    },
    {
        name: "LLaVA",
        author: "University of Wisconsin",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Large Language and Vision Assistant for visual instruction following.",
        plainDescription: "AI that can see and understand images while having conversations about them. Upload photos and ask questions, get descriptions, or request analysis.",
        useCases: ["Image Analysis", "Visual Q&A", "Photo Description", "Educational Assistance", "Accessibility Support"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B - 13B",
            memoryRequired: "14GB - 26GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "620K",
        stars: "15.2K",
        date: "2023-04-17",
        tags: ["vision-language", "instruction-following", "multimodal"],
        githubUrl: "https://github.com/haotian-liu/LLaVA",
        huggingtfaceUrl: "https://huggingface.co/liuhaotian/llava-v1.5-13b"
    },
    {
        name: "E5",
        author: "Microsoft",
        provider: "Hugging Face",
        category: "embedding",
        description: "Text embeddings by weakly-supervised contrastive pre-training.",
        plainDescription: "Advanced text understanding model that creates meaningful representations of text for search and similarity tasks across multiple languages.",
        useCases: ["Multilingual Search", "Document Retrieval", "Text Classification", "Semantic Matching", "Cross-lingual Tasks"],
        inputModalities: ["Text"],
        outputModalities: ["Embeddings"],
        technicalSpecs: {
            parameters: "110M - 335M",
            memoryRequired: "1GB - 3GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Sentence-Transformers", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "890K",
        stars: "1.8K",
        date: "2022-12-07",
        tags: ["text-embeddings", "retrieval", "contrastive-learning"],
        githubUrl: "https://github.com/microsoft/unilm/tree/master/e5",
        huggingtfaceUrl: "https://huggingface.co/intfloat/e5-large-v2"
    },
    {
        name: "Falcon",
        author: "Technology Innovation Institute",
        provider: "Hugging Face",
        category: "language",
        description: "Foundation language model trained on RefinedWeb dataset with strong performance.",
        plainDescription: "Powerful conversational AI that excels at creative writing, problem-solving, and multilingual tasks with efficient performance and open licensing.",
        useCases: ["Creative Writing", "Code Generation", "Multilingual Chat", "Content Creation", "Research Assistance"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B - 180B",
            memoryRequired: "14GB - 360GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "GGUF", "AWQ", "GPTQ"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "$0.50",
            outputCost: "$1.50"
        },
        license: "Apache-2.0",
        downloads: "1.1M",
        stars: "6.8K",
        date: "2023-05-24",
        tags: ["large-language-model", "refined-web", "multilingual"],
        githubUrl: "https://github.com/Technology-Innovation-Institute/falcon",
        huggingtfaceUrl: "https://huggingface.co/tiiuae/falcon-40b"
    },
    {
        name: "SAM",
        author: "Meta",
        provider: "Hugging Face",
        category: "vision",
        description: "Segment Anything Model - promptable segmentation system with zero-shot generalization.",
        plainDescription: "Precisely cuts out any object from images by clicking on it. Works on any image without training, perfect for photo editing and object isolation.",
        useCases: ["Photo Editing", "Medical Imaging", "Autonomous Driving", "Content Creation", "Quality Inspection"],
        inputModalities: ["Image"],
        outputModalities: ["Masks"],
        technicalSpecs: {
            parameters: "90M - 640M",
            memoryRequired: "4GB - 8GB VRAM",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "ONNX", "TensorRT"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "750K",
        stars: "42.1K",
        date: "2023-04-05",
        tags: ["segmentation", "zero-shot", "computer-vision"],
        githubUrl: "https://github.com/facebookresearch/segment-anything",
        huggingtfaceUrl: "https://huggingface.co/facebook/sam-vit-large"
    },
    {
        name: "GPT-J",
        author: "EleutherAI",
        provider: "Hugging Face",
        category: "language",
        description: "6 billion parameter autoregressive language model trained on The Pile dataset.",
        plainDescription: "Open-source alternative to GPT-3 that can write stories, answer questions, generate code, and have conversations.",
        useCases: ["Text Generation", "Story Writing", "Code Completion", "Question Answering", "Creative Writing"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "6B",
            memoryRequired: "12GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "GGUF", "JAX"],
            toolCalling: "No",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "1.8M",
        stars: "9.2K",
        date: "2021-05-03",
        tags: ["autoregressive", "language-generation", "open-source"],
        githubUrl: "https://github.com/kingoflolz/mesh-transformer-jax",
        huggingtfaceUrl: "https://huggingface.co/EleutherAI/gpt-j-6b"
    },
    {
        name: "GPT-NeoX",
        author: "EleutherAI",
        provider: "Hugging Face",
        category: "language",
        description: "20 billion parameter language model implementing GPT-3 architecture.",
        plainDescription: "Large-scale AI for advanced text generation, creative writing, and complex reasoning tasks with high-quality outputs.",
        useCases: ["Research", "Content Generation", "Complex Reasoning", "Creative Writing", "Code Generation"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "20B",
            memoryRequired: "40GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "GGUF", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "890K",
        stars: "7.1K",
        date: "2022-02-09",
        tags: ["large-language-model", "gpt-architecture", "research"],
        githubUrl: "https://github.com/EleutherAI/gpt-neox",
        huggingtfaceUrl: "https://huggingface.co/EleutherAI/gpt-neox-20b"
    },
    {
        name: "Alpaca",
        author: "Stanford",
        provider: "Hugging Face",
        category: "language",
        description: "Instruction-following model fine-tuned from LLaMA with 52K instruction-following examples.",
        plainDescription: "Fine-tuned AI assistant that follows instructions well, perfect for educational tasks and helpful conversations.",
        useCases: ["Education", "Instruction Following", "Tutoring", "Research Assistant", "Task Completion"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B - 65B",
            memoryRequired: "14GB - 130GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "GGUF", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "1.3M",
        stars: "26.4K",
        date: "2023-03-13",
        tags: ["instruction-tuning", "fine-tuned", "educational"],
        githubUrl: "https://github.com/tatsu-lab/stanford_alpaca",
        huggingtfaceUrl: "https://huggingface.co/tatsu-lab/alpaca-7b-wdiff"
    },
    {
        name: "Vicuna",
        author: "UC Berkeley",
        provider: "Hugging Face",
        category: "language",
        description: "Open-source chatbot trained by fine-tuning LLaMA on user-shared conversations.",
        plainDescription: "Conversational AI trained on real chat data that excels at dialogue and maintaining context in long conversations.",
        useCases: ["Chatbots", "Customer Service", "Personal Assistant", "Dialogue Systems", "Interactive AI"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B - 33B",
            memoryRequired: "14GB - 66GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "GGUF", "FastChat"],
            toolCalling: "Yes",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "2.1M",
        stars: "33.8K",
        date: "2023-03-30",
        tags: ["conversational-ai", "chat", "fine-tuned"],
        githubUrl: "https://github.com/lm-sys/FastChat",
        huggingtfaceUrl: "https://huggingface.co/lmsys/vicuna-13b-v1.5"
    },
    {
        name: "OpenAssistant",
        author: "LAION",
        provider: "Hugging Face",
        category: "language",
        description: "Open-source conversational AI assistant trained to be helpful, harmless, and honest.",
        plainDescription: "Community-built AI assistant designed to be helpful and safe, trained with human feedback on diverse tasks.",
        useCases: ["General Assistant", "Educational Support", "Creative Tasks", "Code Help", "Information Retrieval"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "12B - 30B",
            memoryRequired: "24GB - 60GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "GGUF", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "780K",
        stars: "35.9K",
        date: "2023-04-15",
        tags: ["assistant", "human-feedback", "community"],
        githubUrl: "https://github.com/LAION-AI/Open-Assistant",
        huggingtfaceUrl: "https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5"
    },
    {
        name: "MPT",
        author: "MosaicML",
        provider: "Hugging Face",
        category: "language",
        description: "MosaicML Pretrained Transformer with commercial use license and optimized training.",
        plainDescription: "Commercial-friendly AI model optimized for business use with strong performance on various language tasks.",
        useCases: ["Commercial Applications", "Business Intelligence", "Content Creation", "Data Analysis", "Enterprise AI"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B - 30B",
            memoryRequired: "14GB - 60GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "GGUF", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "950K",
        stars: "5.1K",
        date: "2023-05-05",
        tags: ["commercial-use", "optimized", "enterprise"],
        githubUrl: "https://github.com/mosaicml/llm-foundry",
        huggingtfaceUrl: "https://huggingface.co/mosaicml/mpt-7b"
    },
    {
        name: "RedPajama",
        author: "Together",
        provider: "Hugging Face",
        category: "language",
        description: "Open reproduction of LLaMA trained on RedPajama dataset for full transparency.",
        plainDescription: "Transparent AI model with openly available training data, perfect for research and applications requiring full reproducibility.",
        useCases: ["Research", "Reproducible AI", "Academic Studies", "Transparent ML", "Educational Projects"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "3B - 7B",
            memoryRequired: "6GB - 14GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "GGUF", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "1.2M",
        stars: "4.5K",
        date: "2023-04-17",
        tags: ["reproducible", "transparent", "open-data"],
        githubUrl: "https://github.com/togethercomputer/RedPajama-Data",
        huggingtfaceUrl: "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base"
    },
    {
        name: "Dolly",
        author: "Databricks",
        provider: "Hugging Face",
        category: "language",
        description: "Instruction-following large language model trained on human-generated instruction dataset.",
        plainDescription: "Business-focused AI assistant trained specifically for following complex instructions and enterprise applications.",
        useCases: ["Enterprise AI", "Instruction Following", "Business Analytics", "Data Processing", "Corporate Assistant"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "3B - 12B",
            memoryRequired: "6GB - 24GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "CC-BY-SA",
        downloads: "680K",
        stars: "6.3K",
        date: "2023-04-12",
        tags: ["instruction-following", "enterprise", "databricks"],
        githubUrl: "https://github.com/databrickslabs/dolly",
        huggingtfaceUrl: "https://huggingface.co/databricks/dolly-v2-12b"
    },
    {
        name: "FLAN-T5",
        author: "Google",
        provider: "Hugging Face",
        category: "language",
        description: "Instruction-tuned version of T5 trained on 1000+ tasks with detailed instructions.",
        plainDescription: "Google's instruction-following AI that excels at understanding and completing a wide variety of specific tasks and commands.",
        useCases: ["Task Automation", "Instruction Following", "Multi-task Learning", "Zero-shot Tasks", "Educational AI"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "80M - 11B",
            memoryRequired: "1GB - 22GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "TensorFlow", "JAX", "ONNX"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "2.3M",
        stars: "8.7K",
        date: "2022-10-20",
        tags: ["instruction-tuning", "multi-task", "google"],
        githubUrl: "https://github.com/google-research/t5x",
        huggingtfaceUrl: "https://huggingface.co/google/flan-t5-large"
    },
    {
        name: "ChatGLM",
        author: "Tsinghua University",
        provider: "Hugging Face",
        category: "language",
        description: "Bilingual conversational language model supporting both Chinese and English.",
        plainDescription: "Bilingual AI assistant optimized for Chinese and English conversations with strong reasoning and code generation abilities.",
        useCases: ["Multilingual Chat", "Chinese NLP", "Cross-lingual Tasks", "Educational Support", "Bilingual Content"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "6B - 130B",
            memoryRequired: "12GB - 260GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "1.5M",
        stars: "17.2K",
        date: "2023-03-14",
        tags: ["bilingual", "chinese", "conversational"],
        githubUrl: "https://github.com/THUDM/ChatGLM-6B",
        huggingtfaceUrl: "https://huggingface.co/THUDM/chatglm-6b"
    },
    {
        name: "WizardCoder",
        author: "WizardLM",
        provider: "Hugging Face",
        category: "language",
        description: "Code-specialized language model fine-tuned for programming tasks and code generation.",
        plainDescription: "Advanced coding AI that excels at programming tasks, debugging, code explanation, and software development across multiple languages.",
        useCases: ["Code Generation", "Programming Help", "Debugging", "Code Review", "Software Development"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "15B - 34B",
            memoryRequired: "30GB - 68GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "GGUF", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "750K",
        stars: "9.8K",
        date: "2023-06-14",
        tags: ["code-generation", "programming", "wizard"],
        githubUrl: "https://github.com/nlpxucan/WizardLM",
        huggingtfaceUrl: "https://huggingface.co/WizardLM/WizardCoder-15B-V1.0"
    },
    {
        name: "Phind CodeLlama",
        author: "Phind",
        provider: "Hugging Face",
        category: "language",
        description: "Fine-tuned CodeLlama model optimized for code generation and programming assistance.",
        plainDescription: "Specialized programming AI optimized for real-world coding tasks with excellent performance on code completion and generation.",
        useCases: ["Code Completion", "Programming Assistant", "Software Development", "Algorithm Design", "Code Optimization"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "34B",
            memoryRequired: "68GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "GGUF", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Custom",
        downloads: "520K",
        stars: "2.1K",
        date: "2023-08-24",
        tags: ["code-generation", "programming", "fine-tuned"],
        githubUrl: "https://github.com/phind-com/Phind-CodeLlama-34B-v2",
        huggingtfaceUrl: "https://huggingface.co/Phind/Phind-CodeLlama-34B-v2"
    },
    {
        name: "ResNet",
        author: "Microsoft",
        provider: "PyTorch Hub",
        category: "vision",
        description: "Deep residual networks for image recognition with skip connections.",
        plainDescription: "Fundamental computer vision model that classifies images into thousands of categories with high accuracy and efficiency.",
        useCases: ["Image Classification", "Feature Extraction", "Transfer Learning", "Computer Vision Research", "Backbone Networks"],
        inputModalities: ["Image"],
        outputModalities: ["Classifications"],
        technicalSpecs: {
            parameters: "11M - 60M",
            memoryRequired: "2GB VRAM",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "ONNX", "TensorFlow", "CoreML"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "BSD-3-Clause",
        downloads: "5.2M",
        stars: "28.4K",
        date: "2015-12-10",
        tags: ["image-classification", "computer-vision", "backbone"],
        githubUrl: "https://github.com/pytorch/vision",
        huggingtfaceUrl: "https://huggingface.co/microsoft/resnet-50"
    },
    {
        name: "EfficientNet",
        author: "Google",
        provider: "TensorFlow Hub",
        category: "vision",
        description: "Efficient convolutional neural networks for image classification with optimal accuracy-efficiency trade-off.",
        plainDescription: "Highly efficient image classifier that achieves state-of-the-art accuracy while using significantly fewer computational resources.",
        useCases: ["Mobile Applications", "Edge Computing", "Efficient Classification", "Resource-Constrained Deployment", "Real-time Processing"],
        inputModalities: ["Image"],
        outputModalities: ["Classifications"],
        technicalSpecs: {
            parameters: "5M - 66M",
            memoryRequired: "1GB - 4GB VRAM",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Very Fast",
            formats: ["TensorFlow", "PyTorch", "ONNX", "TensorRT"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "3.8M",
        stars: "12.1K",
        date: "2019-05-28",
        tags: ["efficient", "mobile", "classification"],
        githubUrl: "https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet",
        huggingtfaceUrl: "https://huggingface.co/google/efficientnet-b7"
    },
    {
        name: "Vision Transformer (ViT)",
        author: "Google",
        provider: "Hugging Face",
        category: "vision",
        description: "Pure transformer applied to image patches for image classification without convolutions.",
        plainDescription: "Revolutionary computer vision model that treats images like text, using attention mechanisms for superior image understanding.",
        useCases: ["Image Classification", "Vision Research", "Transfer Learning", "Medical Imaging", "Fine-grained Recognition"],
        inputModalities: ["Image"],
        outputModalities: ["Classifications"],
        technicalSpecs: {
            parameters: "86M - 632M",
            memoryRequired: "4GB - 8GB VRAM",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "JAX", "TensorFlow", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "2.1M",
        stars: "18.3K",
        date: "2020-10-22",
        tags: ["transformer", "attention", "vision"],
        githubUrl: "https://github.com/google-research/vision_transformer",
        huggingtfaceUrl: "https://huggingface.co/google/vit-large-patch16-224"
    },
    {
        name: "DINOv2",
        author: "Meta",
        provider: "Hugging Face",
        category: "vision",
        description: "Self-supervised Vision Transformer for learning robust visual features without labels.",
        plainDescription: "Advanced computer vision model that learns to understand images without needing labeled training data, excellent for feature extraction.",
        useCases: ["Feature Extraction", "Self-supervised Learning", "Image Representation", "Transfer Learning", "Computer Vision Research"],
        inputModalities: ["Image"],
        outputModalities: ["Features"],
        technicalSpecs: {
            parameters: "22M - 1.1B",
            memoryRequired: "2GB - 8GB VRAM",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "890K",
        stars: "7.2K",
        date: "2023-04-14",
        tags: ["self-supervised", "feature-extraction", "vision-transformer"],
        githubUrl: "https://github.com/facebookresearch/dinov2",
        huggingtfaceUrl: "https://huggingface.co/facebook/dinov2-large"
    },
    {
        name: "ConvNeXt",
        author: "Meta",
        provider: "Hugging Face",
        category: "vision",
        description: "Modernized ConvNet that competes with Vision Transformers using pure convolutions.",
        plainDescription: "Modern convolutional neural network that combines the best of traditional CNN design with transformer innovations for excellent image recognition.",
        useCases: ["Image Classification", "Object Detection", "Semantic Segmentation", "Feature Extraction", "Computer Vision Backbone"],
        inputModalities: ["Image"],
        outputModalities: ["Classifications", "Features"],
        technicalSpecs: {
            parameters: "28M - 197M",
            memoryRequired: "3GB - 6GB VRAM",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "1.1M",
        stars: "12.8K",
        date: "2022-01-10",
        tags: ["convnet", "modern", "backbone"],
        githubUrl: "https://github.com/facebookresearch/ConvNeXt",
        huggingtfaceUrl: "https://huggingface.co/facebook/convnext-large-224"
    },
    {
        name: "Swin Transformer",
        author: "Microsoft",
        provider: "Hugging Face",
        category: "vision",
        description: "Hierarchical Vision Transformer using shifted windows for efficient computation.",
        plainDescription: "Efficient transformer for computer vision that processes images hierarchically, excellent for various vision tasks with manageable computational cost.",
        useCases: ["Object Detection", "Semantic Segmentation", "Instance Segmentation", "Image Classification", "Vision Backbone"],
        inputModalities: ["Image"],
        outputModalities: ["Classifications", "Features"],
        technicalSpecs: {
            parameters: "28M - 197M",
            memoryRequired: "3GB - 6GB VRAM",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "950K",
        stars: "11.2K",
        date: "2021-03-25",
        tags: ["hierarchical", "efficient", "windows"],
        githubUrl: "https://github.com/microsoft/Swin-Transformer",
        huggingtfaceUrl: "https://huggingface.co/microsoft/swin-large-patch4-window7-224"
    },
    {
        name: "DETR",
        author: "Meta",
        provider: "Hugging Face",
        category: "vision",
        description: "End-to-end object detection with transformers, eliminating need for anchor generation.",
        plainDescription: "Revolutionary object detection model that finds and identifies objects in images using transformers, providing clean bounding boxes and labels.",
        useCases: ["Object Detection", "Instance Segmentation", "Scene Understanding", "Autonomous Driving", "Surveillance"],
        inputModalities: ["Image"],
        outputModalities: ["Bounding Boxes", "Labels"],
        technicalSpecs: {
            parameters: "41M",
            memoryRequired: "4GB VRAM",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "680K",
        stars: "11.8K",
        date: "2020-05-26",
        tags: ["object-detection", "transformer", "end-to-end"],
        githubUrl: "https://github.com/facebookresearch/detr",
        huggingtfaceUrl: "https://huggingface.co/facebook/detr-resnet-50"
    },
    {
        name: "Mask R-CNN",
        author: "Meta",
        provider: "Detectron2",
        category: "vision",
        description: "Framework for object instance segmentation extending Faster R-CNN with mask prediction.",
        plainDescription: "Advanced computer vision model that not only detects objects but also creates precise pixel-level masks showing exactly where each object is located.",
        useCases: ["Instance Segmentation", "Medical Imaging", "Autonomous Vehicles", "Robotics", "Image Analysis"],
        inputModalities: ["Image"],
        outputModalities: ["Masks", "Bounding Boxes", "Labels"],
        technicalSpecs: {
            parameters: "44M",
            memoryRequired: "4GB VRAM",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Detectron2", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "1.8M",
        stars: "25.1K",
        date: "2017-03-20",
        tags: ["instance-segmentation", "object-detection", "mask"],
        githubUrl: "https://github.com/facebookresearch/detectron2",
        huggingtfaceUrl: "https://huggingface.co/facebook/maskrcnn-resnet50-fpn"
    },
    {
        name: "Wav2Vec2",
        author: "Meta",
        provider: "Hugging Face",
        category: "audio",
        description: "Self-supervised learning framework for speech representation from raw audio.",
        plainDescription: "Advanced speech recognition model that learns to understand speech without transcripts, excellent for low-resource languages and speech analysis.",
        useCases: ["Speech Recognition", "Audio Analysis", "Low-resource Languages", "Speech-to-Text", "Audio Classification"],
        inputModalities: ["Audio"],
        outputModalities: ["Text", "Features"],
        technicalSpecs: {
            parameters: "95M - 317M",
            memoryRequired: "2GB - 4GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "1.2M",
        stars: "16.4K",
        date: "2020-06-20",
        tags: ["self-supervised", "speech-recognition", "wav2vec"],
        githubUrl: "https://github.com/facebookresearch/fairseq",
        huggingtfaceUrl: "https://huggingface.co/facebook/wav2vec2-large-960h"
    },
    {
        name: "SpeechT5",
        author: "Microsoft",
        provider: "Hugging Face",
        category: "audio",
        description: "Unified-modal encoder-decoder pre-trained model for spoken language processing.",
        plainDescription: "Versatile speech AI that can both understand and generate speech, perfect for text-to-speech and speech enhancement applications.",
        useCases: ["Text-to-Speech", "Speech Enhancement", "Voice Conversion", "Speech Synthesis", "Audio Processing"],
        inputModalities: ["Text", "Audio"],
        outputModalities: ["Audio"],
        technicalSpecs: {
            parameters: "144M",
            memoryRequired: "2GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "750K",
        stars: "4.2K",
        date: "2021-10-18",
        tags: ["text-to-speech", "speech-synthesis", "unified"],
        githubUrl: "https://github.com/microsoft/SpeechT5",
        huggingtfaceUrl: "https://huggingface.co/microsoft/speecht5_tts"
    },
    {
        name: "VALL-E X",
        author: "Microsoft",
        provider: "GitHub",
        category: "audio",
        description: "Cross-lingual neural codec language model for zero-shot text-to-speech synthesis.",
        plainDescription: "Advanced voice cloning AI that can mimic any voice in multiple languages with just a few seconds of sample audio.",
        useCases: ["Voice Cloning", "Multilingual TTS", "Audiobook Creation", "Voice Acting", "Language Learning"],
        inputModalities: ["Text", "Audio"],
        outputModalities: ["Audio"],
        technicalSpecs: {
            parameters: "600M",
            memoryRequired: "8GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Medium",
            formats: ["PyTorch"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "120K",
        stars: "6.8K",
        date: "2023-07-31",
        tags: ["voice-cloning", "multilingual", "zero-shot"],
        githubUrl: "https://github.com/Plachtaa/VALL-E-X",
        huggingtfaceUrl: "https://huggingface.co/Plachta/VALL-E-X"
    },
    {
        name: "Bark",
        author: "Suno AI",
        provider: "Hugging Face",
        category: "audio",
        description: "Transformer-based text-to-audio model that generates speech, music, and sound effects.",
        plainDescription: "Creative audio AI that generates realistic speech, music, and sound effects from text descriptions with emotional expression and multilingual support.",
        useCases: ["Creative Audio", "Podcast Creation", "Sound Effects", "Multilingual Speech", "Audio Content"],
        inputModalities: ["Text"],
        outputModalities: ["Audio"],
        technicalSpecs: {
            parameters: "1.7B",
            memoryRequired: "12GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Slow",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "890K",
        stars: "31.2K",
        date: "2023-04-07",
        tags: ["text-to-audio", "creative", "multilingual"],
        githubUrl: "https://github.com/suno-ai/bark",
        huggingtfaceUrl: "https://huggingface.co/suno/bark"
    },
    {
        name: "Tortoise TTS",
        author: "James Betker",
        provider: "GitHub",
        category: "audio",
        description: "Multi-voice text-to-speech system focused on quality over speed.",
        plainDescription: "High-quality text-to-speech system that produces exceptionally natural-sounding voices, though slower than real-time generation.",
        useCases: ["High-Quality TTS", "Audiobook Production", "Voice Acting", "Content Creation", "Accessibility"],
        inputModalities: ["Text"],
        outputModalities: ["Audio"],
        technicalSpecs: {
            parameters: "2.8B",
            memoryRequired: "8GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Slow",
            formats: ["PyTorch"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "180K",
        stars: "11.5K",
        date: "2022-05-12",
        tags: ["high-quality", "text-to-speech", "multi-voice"],
        githubUrl: "https://github.com/neonbjb/tortoise-tts",
        huggingtfaceUrl: "https://huggingface.co/Tortoise-TTS"
    },
    {
        name: "FastSpeech2",
        author: "Microsoft",
        provider: "GitHub",
        category: "audio",
        description: "Fast and high-quality neural text-to-speech synthesis with controllable prosody.",
        plainDescription: "Fast, controllable text-to-speech system that allows fine control over speaking speed, pitch, and rhythm for natural voice synthesis.",
        useCases: ["Real-time TTS", "Voice Assistants", "Controllable Speech", "Interactive Applications", "Accessibility Tools"],
        inputModalities: ["Text"],
        outputModalities: ["Audio"],
        technicalSpecs: {
            parameters: "28M",
            memoryRequired: "1GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "320K",
        stars: "1.8K",
        date: "2020-06-08",
        tags: ["fast", "controllable", "real-time"],
        githubUrl: "https://github.com/ming024/FastSpeech2",
        huggingtfaceUrl: "https://huggingface.co/espnet/fastspeech2"
    },
    {
        name: "BLIP",
        author: "Salesforce",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Bootstrapping Language-Image Pre-training for unified vision-language understanding and generation.",
        plainDescription: "Versatile AI that understands both images and text, capable of describing images, answering visual questions, and generating captions.",
        useCases: ["Image Captioning", "Visual Question Answering", "Image-Text Retrieval", "Content Moderation", "Accessibility"],
        inputModalities: ["Image", "Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "224M",
            memoryRequired: "4GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "BSD-3-Clause",
        downloads: "1.1M",
        stars: "4.2K",
        date: "2022-01-28",
        tags: ["vision-language", "captioning", "vqa"],
        githubUrl: "https://github.com/salesforce/BLIP",
        huggingtfaceUrl: "https://huggingface.co/Salesforce/blip-image-captioning-large"
    },
    {
        name: "BLIP-2",
        author: "Salesforce",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Bootstrapped vision-language pre-training with frozen image encoders and language models.",
        plainDescription: "Advanced multimodal AI that connects powerful vision and language models for superior image understanding and conversational abilities.",
        useCases: ["Visual Conversations", "Image Analysis", "Educational AI", "Content Creation", "Research Assistant"],
        inputModalities: ["Image", "Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "2.7B - 7.8B",
            memoryRequired: "16GB - 32GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "BSD-3-Clause",
        downloads: "680K",
        stars: "8.1K",
        date: "2023-01-30",
        tags: ["vision-language", "frozen-models", "conversation"],
        githubUrl: "https://github.com/salesforce/LAVIS",
        huggingtfaceUrl: "https://huggingface.co/Salesforce/blip2-opt-2.7b"
    },
    {
        name: "Flamingo",
        author: "DeepMind",
        provider: "GitHub",
        category: "multimodal",
        description: "Few-shot learning vision-language model for multimodal understanding tasks.",
        plainDescription: "Advanced AI that learns to understand new visual concepts from just a few examples, excellent for rapid adaptation to new tasks.",
        useCases: ["Few-shot Learning", "Visual Reasoning", "Multimodal Research", "Adaptive AI", "Educational Technology"],
        inputModalities: ["Image", "Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "80B",
            memoryRequired: "160GB",
            hardwareRequirement: "Multiple GPUs",
            inferenceSpeed: "Slow",
            formats: ["JAX"],
            toolCalling: "No",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "45K",
        stars: "3.1K",
        date: "2022-04-29",
        tags: ["few-shot", "vision-language", "deepmind"],
        githubUrl: "https://github.com/deepmind/flamingo",
        huggingtfaceUrl: "https://huggingface.co/deepmind/flamingo"
    },
    {
        name: "InstructBLIP",
        author: "Salesforce",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Instruction-tuned vision-language model for following complex visual instructions.",
        plainDescription: "Multimodal AI assistant that follows detailed instructions about images, perfect for complex visual analysis and educational applications.",
        useCases: ["Visual Instruction Following", "Educational AI", "Image Analysis", "Content Moderation", "Accessibility Support"],
        inputModalities: ["Image", "Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B - 13B",
            memoryRequired: "14GB - 26GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "BSD-3-Clause",
        downloads: "420K",
        stars: "5.7K",
        date: "2023-05-11",
        tags: ["instruction-following", "vision-language", "multimodal"],
        githubUrl: "https://github.com/salesforce/LAVIS",
        huggingtfaceUrl: "https://huggingface.co/Salesforce/instructblip-vicuna-7b"
    },
    {
        name: "LayoutLM",
        author: "Microsoft",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Pre-trained model for document understanding combining text, layout, and image information.",
        plainDescription: "Specialized AI for understanding documents that considers both text content and visual layout, perfect for forms, invoices, and structured documents.",
        useCases: ["Document Processing", "Form Understanding", "Invoice Analysis", "Information Extraction", "OCR Enhancement"],
        inputModalities: ["Image", "Text"],
        outputModalities: ["Text", "Annotations"],
        technicalSpecs: {
            parameters: "113M - 344M",
            memoryRequired: "2GB - 4GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers", "ONNX"],
            toolCalling: "No",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "950K",
        stars: "3.8K",
        date: "2019-12-31",
        tags: ["document-understanding", "layout", "ocr"],
        githubUrl: "https://github.com/microsoft/unilm",
        huggingtfaceUrl: "https://huggingface.co/microsoft/layoutlm-base-uncased"
    },
    {
        name: "ALIGN",
        author: "Google",
        provider: "GitHub",
        category: "multimodal",
        description: "Large-scale noisy image-text alignment without manual data curation.",
        plainDescription: "Vision-language model trained on massive web data that excels at understanding relationships between images and text descriptions.",
        useCases: ["Image-Text Matching", "Content Discovery", "Visual Search", "Cross-modal Retrieval", "Multimodal Research"],
        inputModalities: ["Image", "Text"],
        outputModalities: ["Embeddings"],
        technicalSpecs: {
            parameters: "1.8B",
            memoryRequired: "8GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["TensorFlow", "JAX"],
            toolCalling: "No",
            reasoning: "Basic",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "180K",
        stars: "2.1K",
        date: "2021-02-11",
        tags: ["alignment", "noisy-data", "large-scale"],
        githubUrl: "https://github.com/google-research/google-research/tree/master/align",
        huggingtfaceUrl: "https://huggingface.co/google/align"
    },
    {
        name: "CogVLM",
        author: "Tsinghua University",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Powerful open-source visual language model supporting image understanding and generation.",
        plainDescription: "Advanced Chinese-English bilingual AI that understands images and can have detailed conversations about visual content with strong reasoning abilities.",
        useCases: ["Bilingual Vision Chat", "Image Analysis", "Visual Reasoning", "Educational Support", "Multimodal Research"],
        inputModalities: ["Image", "Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "17B",
            memoryRequired: "34GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "280K",
        stars: "5.2K",
        date: "2023-10-25",
        tags: ["bilingual", "vision-language", "reasoning"],
        githubUrl: "https://github.com/THUDM/CogVLM",
        huggingtfaceUrl: "https://huggingface.co/THUDM/cogvlm-chat-hf"
    },
    {
        name: "BGE",
        author: "BAAI",
        provider: "Hugging Face",
        category: "embedding",
        description: "General embedding model for text retrieval and representation learning.",
        plainDescription: "High-performance text embedding model optimized for search and retrieval tasks with excellent multilingual capabilities.",
        useCases: ["Semantic Search", "Document Retrieval", "Text Similarity", "RAG Systems", "Multilingual Search"],
        inputModalities: ["Text"],
        outputModalities: ["Embeddings"],
        technicalSpecs: {
            parameters: "33M - 335M",
            memoryRequired: "1GB - 3GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "Sentence-Transformers", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "2.1M",
        stars: "4.8K",
        date: "2023-09-11",
        tags: ["embeddings", "retrieval", "multilingual"],
        githubUrl: "https://github.com/FlagOpen/FlagEmbedding",
        huggingtfaceUrl: "https://huggingface.co/BAAI/bge-large-en-v1.5"
    },
    {
        name: "Instructor",
        author: "HKU NLP",
        provider: "Hugging Face",
        category: "embedding",
        description: "Instruction-following text embedding model for diverse embedding tasks.",
        plainDescription: "Flexible embedding model that follows natural language instructions to create specialized embeddings for different tasks and domains.",
        useCases: ["Instruction-based Embeddings", "Task-specific Search", "Domain Adaptation", "Flexible Retrieval", "Custom Applications"],
        inputModalities: ["Text"],
        outputModalities: ["Embeddings"],
        technicalSpecs: {
            parameters: "110M - 335M",
            memoryRequired: "1GB - 3GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Sentence-Transformers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "1.5M",
        stars: "1.9K",
        date: "2022-12-20",
        tags: ["instruction-following", "flexible", "task-specific"],
        githubUrl: "https://github.com/xlang-ai/instructor-embedding",
        huggingtfaceUrl: "https://huggingface.co/hkunlp/instructor-large"
    },
    {
        name: "Universal Sentence Encoder",
        author: "Google",
        provider: "TensorFlow Hub",
        category: "embedding",
        description: "Pre-trained encoder for generating sentence embeddings across multiple tasks.",
        plainDescription: "Google's versatile text encoder that creates meaningful sentence representations for various NLP tasks and multilingual applications.",
        useCases: ["Sentence Similarity", "Text Classification", "Clustering", "Semantic Search", "Cross-lingual Tasks"],
        inputModalities: ["Text"],
        outputModalities: ["Embeddings"],
        technicalSpecs: {
            parameters: "147M",
            memoryRequired: "1GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["TensorFlow", "TensorFlow Hub", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "3.5M",
        stars: "8.2K",
        date: "2018-03-29",
        tags: ["universal", "sentence", "multilingual"],
        githubUrl: "https://github.com/tensorflow/hub",
        huggingtfaceUrl: "https://huggingface.co/google/universal-sentence-encoder"
    },
    {
        name: "SimCSE",
        author: "Princeton NLP",
        provider: "Hugging Face",
        category: "embedding",
        description: "Simple contrastive learning framework for sentence embeddings.",
        plainDescription: "Efficient method for creating high-quality sentence embeddings using contrastive learning, excellent for similarity tasks and clustering.",
        useCases: ["Sentence Similarity", "Semantic Textual Similarity", "Information Retrieval", "Clustering", "Duplicate Detection"],
        inputModalities: ["Text"],
        outputModalities: ["Embeddings"],
        technicalSpecs: {
            parameters: "110M - 335M",
            memoryRequired: "1GB - 3GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers", "Sentence-Transformers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "890K",
        stars: "2.8K",
        date: "2021-04-18",
        tags: ["contrastive", "similarity", "simple"],
        githubUrl: "https://github.com/princeton-nlp/SimCSE",
        huggingtfaceUrl: "https://huggingface.co/princeton-nlp/sup-simcse-bert-large-uncased"
    },
    {
        name: "T5",
        author: "Google",
        provider: "Google",
        category: "language",
        description: "Text-to-Text Transfer Transformer that treats every NLP problem as text generation task.",
        plainDescription: "A versatile AI that can handle any text task by converting everything into a text-to-text format - summarization, translation, Q&A, and more.",
        useCases: ["Text Summarization", "Language Translation", "Question Answering", "Text Classification", "Paraphrasing"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "60M - 11B",
            memoryRequired: "1GB - 44GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "TensorFlow", "JAX", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "5.2M",
        stars: "8.9K",
        date: "2019-10-23",
        tags: ["text-to-text", "transfer-learning", "versatile", "google"],
        githubUrl: "https://github.com/google-research/text-to-text-transfer-transformer",
        huggingtfaceUrl: "https://huggingface.co/t5-large"
    },
    {
        name: "DINOv3",
        author: "Meta",
        provider: "Meta",
        category: "vision",
        description: "Breakthrough self-supervised vision model trained on 1.7B images, scaling to 7B parameters with state-of-the-art performance across diverse domains.",
        plainDescription: "Advanced computer vision AI that learns without labels, excelling at image classification, object detection, and semantic segmentation across web and satellite imagery.",
        useCases: ["Image Classification", "Object Detection", "Semantic Segmentation", "Video Object Tracking", "Satellite Imagery Analysis", "Visual Feature Extraction"],
        inputModalities: ["Image"],
        outputModalities: ["Embeddings", "Features"],
        technicalSpecs: {
            parameters: "7B (flagship), ViT-B/L variants",
            memoryRequired: "16GB - 28GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Commercial",
        downloads: "New",
        stars: "New",
        date: "2025-08-14",
        tags: ["self-supervised", "vision-transformer", "foundation-model", "computer-vision", "satellite-imagery"],
        githubUrl: "https://github.com/facebookresearch/dinov3",
        huggingtfaceUrl: "https://huggingface.co/facebook/dinov3"
    },
    {
        name: "Gemma 3 270M",
        author: "Google",
        provider: "Google",
        category: "language",
        description: "Ultra-compact language model with 270M parameters designed for energy-efficient on-device AI and task-specific fine-tuning with strong instruction-following capabilities.",
        plainDescription: "A small but powerful AI model that can understand and follow instructions while using minimal energy, perfect for mobile apps and specialized tasks.",
        useCases: ["On-device AI", "Task-specific Fine-tuning", "Mobile Applications", "Edge Computing", "Specialized Domain Models", "Resource-constrained Environments"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "270M (170M embedding + 100M transformer)",
            memoryRequired: "1GB - 2GB",
            hardwareRequirement: "CPU/GPU/Mobile",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "Transformers", "INT4 Quantized"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "New",
        stars: "New",
        date: "2025-08-14",
        tags: ["compact", "energy-efficient", "on-device", "instruction-following", "fine-tuning", "quantized"],
        githubUrl: "https://github.com/google-deepmind/gemma",
        huggingtfaceUrl: "https://huggingface.co/google/gemma-3-270m"
    },
    {
        name: "LTX-Video",
        author: "Lightricks",
        provider: "Hugging Face",
        category: "multimodal",
        description: "DiT-based video generation model supporting image-to-video and video-to-video generation with high-resolution output up to 1216×704 at 30 FPS.",
        plainDescription: "AI model that creates videos from text descriptions or transforms existing videos, producing high-quality video content up to 1216×704 resolution.",
        useCases: ["Video Generation", "Image-to-Video", "Video-to-Video", "Content Creation", "Video Editing", "Marketing Videos"],
        inputModalities: ["Text", "Image", "Video"],
        outputModalities: ["Video"],
        technicalSpecs: {
            parameters: "2B - 13B variants",
            memoryRequired: "8GB - 24GB VRAM",
            hardwareRequirement: "CUDA GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Diffusers", "FP8 Quantized"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Custom",
        downloads: "50K",
        stars: "2.1K",
        date: "2024-12-10",
        tags: ["video-generation", "dit-transformer", "diffusion", "multimodal", "high-resolution"],
        githubUrl: "https://github.com/Lightricks/LTX-Video",
        huggingtfaceUrl: "https://huggingface.co/Lightricks/LTX-Video"
    },
    {
        name: "Grok-1",
        author: "xAI",
        provider: "Hugging Face",
        category: "language",
        description: "314B parameter mixture-of-experts transformer language model, one of the largest open-source models with 8x33B MoE architecture and 25% active weights.",
        plainDescription: "Massive AI language model that can have conversations, answer questions, and help with complex reasoning tasks. One of the largest open-source models available.",
        useCases: ["Conversational AI", "Complex Reasoning", "Code Generation", "Mathematical Problem Solving", "Creative Writing", "Research Assistance"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "314B (MoE: 8x33B, 25% active)",
            memoryRequired: "600GB+ (full), 150GB+ (active)",
            hardwareRequirement: "Multiple GPUs required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "JAX"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "75K",
        stars: "49.2K",
        date: "2024-03-17",
        tags: ["mixture-of-experts", "large-scale", "reasoning", "open-source", "transformer"],
        githubUrl: "https://github.com/xai-org/grok-1",
        huggingtfaceUrl: "https://huggingface.co/xai-org/grok-1"
    },
    {
        name: "FLUX.1",
        author: "Black Forest Labs",
        provider: "Hugging Face",
        category: "vision",
        description: "12B parameter text-to-image diffusion model with superior prompt adherence and aesthetic quality, created by the original Stable Diffusion team.",
        plainDescription: "Advanced AI that creates high-quality images from text descriptions with excellent prompt following and artistic quality.",
        useCases: ["Art Generation", "Creative Design", "Marketing Materials", "Concept Art", "Product Visualization", "Social Media Content"],
        inputModalities: ["Text"],
        outputModalities: ["Image"],
        technicalSpecs: {
            parameters: "12B",
            memoryRequired: "16GB+ VRAM",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["Diffusers", "ComfyUI", "ONNX"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "120K",
        stars: "15.3K",
        date: "2024-08-01",
        tags: ["text-to-image", "diffusion", "high-quality", "prompt-adherence", "artistic"],
        githubUrl: "https://github.com/black-forest-labs/flux",
        huggingtfaceUrl: "https://huggingface.co/black-forest-labs/FLUX.1-dev"
    },
    {
        name: "MiniCPM-V 2.6",
        author: "OpenBMB",
        provider: "Hugging Face",
        category: "multimodal",
        description: "8B parameter multimodal vision-language model achieving GPT-4V level performance with efficient mobile deployment and excellent OCR capabilities.",
        plainDescription: "AI that can understand both images and text together, with performance matching GPT-4V but small enough to run on mobile devices.",
        useCases: ["Visual Question Answering", "OCR and Document Analysis", "Image Captioning", "Mobile AI Applications", "Visual Reasoning", "Chart Analysis"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "8B",
            memoryRequired: "12GB - 16GB",
            hardwareRequirement: "GPU/Mobile optimized",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers", "ONNX"],
            toolCalling: "Limited",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "85K",
        stars: "8.9K",
        date: "2024-08-20",
        tags: ["multimodal", "vision-language", "mobile-optimized", "ocr", "efficient"],
        githubUrl: "https://github.com/OpenBMB/MiniCPM-V",
        huggingtfaceUrl: "https://huggingface.co/openbmb/MiniCPM-V-2_6"
    },
    {
        name: "Florence-2",
        author: "Microsoft",
        provider: "Hugging Face",
        category: "vision",
        description: "Unified vision foundation model with 0.23B-0.77B parameters demonstrating that small models can achieve high capability across multiple vision tasks.",
        plainDescription: "Efficient computer vision AI that can handle multiple tasks like object detection, segmentation, and captioning in one small model.",
        useCases: ["Object Detection", "Image Segmentation", "Image Captioning", "OCR", "Visual Grounding", "Dense Captioning"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text", "Bounding Boxes", "Masks"],
        technicalSpecs: {
            parameters: "0.23B - 0.77B",
            memoryRequired: "2GB - 4GB",
            hardwareRequirement: "CPU/GPU",
            inferenceSpeed: "Very Fast",
            formats: ["PyTorch", "Transformers", "ONNX"],
            toolCalling: "No",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "95K",
        stars: "12.4K",
        date: "2024-06-17",
        tags: ["vision-foundation", "unified-model", "efficient", "multi-task", "microsoft"],
        githubUrl: "https://github.com/microsoft/Florence",
        huggingtfaceUrl: "https://huggingface.co/microsoft/Florence-2-large"
    },
    {
        name: "Stable Audio Open",
        author: "Stability AI",
        provider: "Hugging Face",
        category: "audio",
        description: "Open-source text-to-audio generation model capable of generating 47-second audio clips, trained on ethical CC-licensed data with commercial viability.",
        plainDescription: "AI that creates audio and music from text descriptions, generating up to 47-second clips with high quality and commercial use rights.",
        useCases: ["Music Generation", "Sound Effects", "Audio Content Creation", "Podcast Intros", "Background Music", "Creative Audio"],
        inputModalities: ["Text"],
        outputModalities: ["Audio"],
        technicalSpecs: {
            parameters: "1.3B",
            memoryRequired: "8GB - 12GB VRAM",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Diffusers"],
            toolCalling: "No",
            reasoning: "None",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "CC-BY-NC-SA-4.0",
        downloads: "45K",
        stars: "7.2K",
        date: "2024-06-25",
        tags: ["text-to-audio", "music-generation", "open-source", "commercial-viable", "diffusion"],
        githubUrl: "https://github.com/Stability-AI/stable-audio-tools",
        huggingtfaceUrl: "https://huggingface.co/stabilityai/stable-audio-open-1.0"
    },
    {
        name: "Qwen2-VL",
        author: "Alibaba",
        provider: "Hugging Face",
        category: "multimodal",
        description: "7B parameter multimodal model with state-of-the-art video understanding capabilities, supporting 20-minute video processing and multilingual OCR.",
        plainDescription: "Advanced AI that can understand both images and videos along with text, capable of analyzing long videos up to 20 minutes and multiple languages.",
        useCases: ["Video Understanding", "Long Video Analysis", "Multilingual OCR", "Visual Question Answering", "Document Analysis", "Video Summarization"],
        inputModalities: ["Text", "Image", "Video"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B",
            memoryRequired: "14GB - 20GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "110K",
        stars: "18.5K",
        date: "2024-09-15",
        tags: ["multimodal", "video-understanding", "multilingual", "long-context", "alibaba"],
        githubUrl: "https://github.com/QwenLM/Qwen2-VL",
        huggingtfaceUrl: "https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct"
    },
    {
        name: "InternVL 2.5",
        author: "Shanghai AI Lab",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Advanced multimodal vision-language model with 6B vision encoder that exceeds 70% on MMMU benchmark, rivaling GPT-4o performance.",
        plainDescription: "State-of-the-art AI that understands images and text together, matching the performance of GPT-4o on complex multimodal reasoning tasks.",
        useCases: ["Visual Reasoning", "Document Analysis", "Chart Understanding", "Scientific Image Analysis", "Multimodal Q&A", "Complex Visual Tasks"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "6B vision encoder + LLM variants",
            memoryRequired: "16GB - 24GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "65K",
        stars: "14.2K",
        date: "2024-11-25",
        tags: ["multimodal", "vision-language", "state-of-the-art", "reasoning", "benchmark-leading"],
        githubUrl: "https://github.com/OpenGVLab/InternVL",
        huggingtfaceUrl: "https://huggingface.co/OpenGVLab/InternVL2_5-8B"
    },
    {
        name: "Janus-Pro",
        author: "DeepSeek",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Unified multimodal model with 1B-7B variants capable of both image understanding and generation, outperforming DALL-E 3 in generation benchmarks.",
        plainDescription: "Versatile AI that can both understand images and generate new ones from text, combining the best of image analysis and creation in one model.",
        useCases: ["Image Generation", "Visual Understanding", "Image Editing", "Creative Design", "Visual Q&A", "Multimodal Reasoning"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text", "Image"],
        technicalSpecs: {
            parameters: "1B - 7B variants",
            memoryRequired: "8GB - 16GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "MIT",
        downloads: "New",
        stars: "New",
        date: "2025-01-15",
        tags: ["unified-multimodal", "image-generation", "understanding", "dall-e-competitor", "deepseek"],
        githubUrl: "https://github.com/deepseek-ai/Janus",
        huggingtfaceUrl: "https://huggingface.co/deepseek-ai/Janus-Pro-7B"
    },
    {
        name: "Llama 4 Scout",
        author: "Meta",
        provider: "Meta",
        category: "multimodal",
        description: "First open-weight natively multimodal Llama model with 17B parameters and 109B total MoE architecture, supporting 128k context length.",
        plainDescription: "Advanced AI that can understand both text and images with native multimodal capabilities, part of Meta's breakthrough Llama 4 series.",
        useCases: ["Multimodal Conversations", "Visual Question Answering", "Document Analysis", "Image Understanding", "Long Context Tasks", "Reasoning"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "17B (109B total MoE)",
            memoryRequired: "32GB - 64GB",
            hardwareRequirement: "Multiple GPUs recommended",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Llama-4",
        downloads: "250K",
        stars: "12.5K",
        date: "2025-04-15",
        tags: ["multimodal", "mixture-of-experts", "long-context", "native-multimodal", "llama-4"],
        githubUrl: "https://github.com/meta-llama/llama4",
        huggingtfaceUrl: "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct"
    },
    {
        name: "Llama 4 Maverick",
        author: "Meta",
        provider: "Meta",
        category: "multimodal",
        description: "Flagship multimodal Llama 4 model with 17B parameters and 400B total MoE architecture, designed for complex multimodal reasoning tasks.",
        plainDescription: "Meta's most powerful open multimodal AI with massive 400B parameter capacity for handling the most complex visual and text understanding tasks.",
        useCases: ["Complex Reasoning", "Advanced Visual Analysis", "Research Applications", "Professional Document Analysis", "Multi-step Problem Solving", "Scientific Tasks"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "17B (400B total MoE)",
            memoryRequired: "64GB - 128GB",
            hardwareRequirement: "Multiple high-end GPUs required",
            inferenceSpeed: "Medium-Slow",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Llama-4",
        downloads: "180K",
        stars: "9.8K",
        date: "2025-04-15",
        tags: ["multimodal", "mixture-of-experts", "flagship", "complex-reasoning", "llama-4"],
        githubUrl: "https://github.com/meta-llama/llama4",
        huggingtfaceUrl: "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
    },
    {
        name: "Gemma 3 27B",
        author: "Google",
        provider: "Google",
        category: "multimodal",
        description: "Advanced multimodal language model with 27B parameters, supporting 128k context window and 140+ languages with native multimodal capabilities.",
        plainDescription: "Google's flagship open multimodal AI that can understand text and images in 140+ languages with massive context understanding.",
        useCases: ["Multilingual Conversations", "Global Content Creation", "Cross-language Analysis", "International Business", "Educational Content", "Cultural Research"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "27B",
            memoryRequired: "48GB - 64GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers", "JAX"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "320K",
        stars: "18.7K",
        date: "2025-03-20",
        tags: ["multimodal", "multilingual", "long-context", "gemma-3", "google"],
        githubUrl: "https://github.com/google-deepmind/gemma",
        huggingtfaceUrl: "https://huggingface.co/google/gemma-3-27b-it"
    },
    {
        name: "DeepSeek R1",
        author: "DeepSeek",
        provider: "Hugging Face",
        category: "language",
        description: "Advanced reasoning language model comparable to OpenAI o1, trained via pure reinforcement learning for enhanced mathematical and logical reasoning capabilities.",
        plainDescription: "AI specialized in complex reasoning tasks like math, logic, and problem-solving, trained to think step-by-step like human experts.",
        useCases: ["Mathematical Problem Solving", "Logical Reasoning", "Scientific Analysis", "Code Debugging", "Complex Planning", "Research Assistance"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "7B - 32B variants",
            memoryRequired: "14GB - 64GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "DeepSeek License",
        downloads: "280K",
        stars: "22.1K",
        date: "2025-01-20",
        tags: ["reasoning", "reinforcement-learning", "mathematics", "o1-competitor", "deepseek"],
        githubUrl: "https://github.com/deepseek-ai/DeepSeek-R1",
        huggingtfaceUrl: "https://huggingface.co/deepseek-ai/DeepSeek-R1"
    },
    {
        name: "SmolVLM-2B",
        author: "Hugging Face",
        provider: "Hugging Face",
        category: "multimodal",
        description: "Compact 2B parameter vision-language model optimized for edge deployment, part of the world's smallest VLM family enabling democratized multimodal AI.",
        plainDescription: "Small but capable AI that can understand both images and text, designed to run efficiently on laptops and mobile devices.",
        useCases: ["Edge AI Applications", "Mobile Visual Apps", "Lightweight Multimodal", "Educational Tools", "Personal Assistants", "IoT Devices"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "2B",
            memoryRequired: "4GB - 8GB",
            hardwareRequirement: "CPU/GPU/Mobile",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers", "ONNX"],
            toolCalling: "Limited",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "150K",
        stars: "8.3K",
        date: "2025-02-10",
        tags: ["small-vlm", "edge-deployment", "mobile-optimized", "efficient", "democratized"],
        githubUrl: "https://github.com/huggingface/SmolVLM",
        huggingtfaceUrl: "https://huggingface.co/HuggingFaceTB/SmolVLM-2B-Instruct"
    },
    {
        name: "Llama Guard 4",
        author: "Meta",
        provider: "Meta",
        category: "multimodal",
        description: "12B parameter multimodal safety model designed for content filtering and safety assessment of both text and images, first major multimodal safety solution.",
        plainDescription: "AI safety system that can detect harmful content in both text and images, helping keep AI applications safe and appropriate.",
        useCases: ["Content Moderation", "Safety Filtering", "Harmful Content Detection", "AI Safety", "Platform Moderation", "Family-Safe AI"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text", "Safety Scores"],
        technicalSpecs: {
            parameters: "12B",
            memoryRequired: "24GB - 32GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "No",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Llama-Guard",
        downloads: "95K",
        stars: "5.7K",
        date: "2025-04-15",
        tags: ["safety-model", "content-moderation", "multimodal-safety", "harm-detection", "meta"],
        githubUrl: "https://github.com/meta-llama/llama-guard",
        huggingtfaceUrl: "https://huggingface.co/meta-llama/Llama-Guard-4-12B"
    },
    {
        name: "ShieldGemma 2",
        author: "Google",
        provider: "Google",
        category: "multimodal",
        description: "4B parameter multimodal safety model built on Gemma 3, representing a breakthrough in AI safety for multimodal systems with comprehensive content filtering.",
        plainDescription: "Google's AI safety system that can identify harmful content in both text and images, built on the advanced Gemma 3 architecture.",
        useCases: ["Multimodal Safety", "Content Filtering", "Harmful Content Detection", "Platform Safety", "Family-Friendly AI", "Compliance Monitoring"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text", "Safety Classifications"],
        technicalSpecs: {
            parameters: "4B",
            memoryRequired: "8GB - 12GB",
            hardwareRequirement: "GPU recommended",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers", "JAX"],
            toolCalling: "No",
            reasoning: "Good",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "75K",
        stars: "4.2K",
        date: "2025-03-01",
        tags: ["multimodal-safety", "content-filtering", "ai-safety", "gemma-based", "google"],
        githubUrl: "https://github.com/google-deepmind/shieldgemma",
        huggingtfaceUrl: "https://huggingface.co/google/shieldgemma-2-4b-it"
    },
    {
        name: "Skywork OR1-32B",
        author: "Skywork AI",
        provider: "Hugging Face",
        category: "language",
        description: "32B parameter mathematical reasoning model specialized for math and coding tasks, demonstrating efficiency competitive with much larger models in specialized domains.",
        plainDescription: "AI specialized in solving complex mathematical problems and coding challenges, designed to compete with much larger models in technical reasoning.",
        useCases: ["Mathematical Problem Solving", "Coding Assistance", "Algorithm Development", "Engineering Calculations", "Academic Research", "Technical Analysis"],
        inputModalities: ["Text"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "32B",
            memoryRequired: "64GB - 80GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Medium",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Yes",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "85K",
        stars: "6.8K",
        date: "2025-04-20",
        tags: ["mathematical-reasoning", "coding", "specialized", "efficient", "skywork"],
        githubUrl: "https://github.com/SkyworkAI/Skywork",
        huggingtfaceUrl: "https://huggingface.co/Skywork/Skywork-OR1-32B-Preview"
    },
    {
        name: "Kimi-VL-A3B-Thinking",
        author: "Moonshot AI",
        provider: "Hugging Face",
        category: "multimodal",
        description: "MoE multimodal reasoning model with 16B total parameters and 2.8B active, optimized for GUI tasks and visual reasoning with thinking capabilities.",
        plainDescription: "Efficient AI that can understand interfaces and visual content while thinking through problems step-by-step, great for GUI automation and visual reasoning.",
        useCases: ["GUI Automation", "Visual Reasoning", "Interface Understanding", "Screen Analysis", "App Testing", "Digital Assistant Tasks"],
        inputModalities: ["Text", "Image"],
        outputModalities: ["Text"],
        technicalSpecs: {
            parameters: "16B total (2.8B active MoE)",
            memoryRequired: "12GB - 20GB",
            hardwareRequirement: "GPU required",
            inferenceSpeed: "Fast",
            formats: ["PyTorch", "Transformers"],
            toolCalling: "Limited",
            reasoning: "Strong",
            inputCost: "Free",
            outputCost: "Free"
        },
        license: "Apache-2.0",
        downloads: "42K",
        stars: "3.5K",
        date: "2025-06-25",
        tags: ["multimodal", "mixture-of-experts", "gui-automation", "thinking", "moonshot"],
        githubUrl: "https://github.com/moonshotai/kimi-vl",
        huggingtfaceUrl: "https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking-2506"
    }
];

module.exports = modelsDatabase;